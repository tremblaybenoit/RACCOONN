# Note: This configuration file is for the ***inverse*** model.


# Location of the data directory  # TODO: Maybe remove this line
dir: ${paths.data_dir}
dtype:
  numpy:
    _target_: numpy.float64  # Data type for arrays
  torch:
    _target_: torch.float64  # Data type for tensors


# Configuration for the variables used in the data loader.
vars:
  prof:
    type: ['Air temperature', 'Water vapor mixing ratio', 'Cloud ice mass', 'Cloud water mass', 'Snow mass',
           'Ice particle effective radius', 'Water particle effective radius',
           'Snow particle effective radius', 'Ozone mixing ratio']
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/prof.npy
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        _target_: inverse.data.statistics.read_statistics_var
        _args_:
          - ${data.preparation.statistics.output.path}
          - 'prof'
      axis: null  # Axis for normalization
  surf:
    type: ['Ice area fraction', 'Land area fraction', 'Land type', 'Leaf area index', 'Soil temperature',
           'Snow area fraction', 'Snow thickness', 'Soil temperature',
           'Surface temperature (ice, land, sea, snow)', 'Wind direction', 'Wind speed',
           'Vegetation area fraction', 'Water area fraction', 'Volumetric water ratio (soil)']
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/surf.npy
    normalization:
      _target_: forward.data.transformations.NormalizeSurface
      _partial_: false
      surfmax:
        _target_: numpy.loadtxt
        _args_:
          - forward/data/normalization/surfmax.txt
      surfmin:
        _target_: numpy.loadtxt
        _args_:
          - forward/data/normalization/surfmin.txt
  meta:
    type: ['Sensor scan angle', 'Sensor zenith angle', 'Sensor view angle', 'Sensor azimuth angle',
            'Sensor elevation angle', 'Solar azimuth angle', 'Solar zenith angle']
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/meta.npy
    normalization:
      _target_: forward.data.transformations.NormalizeMeta
      _partial_: false
      settings:
        meta_cos_vars: [ 6 ]
        meta_scale_factor: 180
        meta_scale_offset: -180
        meta_scale_vars: [ ]
        meta_sin_vars: [ 0, 1, 2, 3, 4, 5 ]
  hofx:
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/hofx_lightning.npy
  lat:
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/lat.npy
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        min: -90.0
        max: 90.0
  lon:
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/lon.npy
  scans:
    load:
      _target_: numpy.loadtxt
      _args_:
        - ${paths.data_dir}/Test2/scans.txt
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        min: 9.0
        max: 180.0
        mean: 88.57895
        stdev: 54.53759
  pressure:
    load:
      _target_: numpy.load
      _args_:
        - ${paths.data_dir}/Test2/pressure.npy
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        min: 0.012935171
        max: 928.14125
        mean: 386.31695
        stdev: 344.8104
  hofx_innovation:
    load:
      _target_: inverse.data.covariance.innovation_uncertainty
      data: ${data.vars.hofx.load}
  prof_background:
    load:
      _target_: inverse.data.covariance.background_climatology
      data: ${data.vars.prof.load}
      cloud_filter: ${data.vars.cloud_filter.load}
    normalization: ${data.vars.prof.normalization}
  prof_increment:  # Note: It applies normalization to the data as specified in the data configuration.
    load:
      _target_: inverse.data.covariance.background_increment
      config_true: ${data.vars.prof}
      config_background: ${data.vars.prof_background}
  pressure_filter:
    load:
      _target_: inverse.data.filters.pressure_filter
      prof: ${data.vars.prof.load}
  cloud_filter:
    load:
      _target_: inverse.data.filters.cloud_filter
      prof: ${data.vars.prof.load}


# Preparation steps to be executed before training or evaluation.
preparation:
  statistics:
    input:
      vars: ${data.vars}
      cloud_filter: ${data.vars.cloud_filter}
    output:
      path: ${paths.data_dir}/normalization/stats_cloud_filter.pkl
      type: file
  covariance:
    model:
      input:
        err: ${data.vars.prof_increment}
        cloud_filter: ${data.vars.cloud_filter}
        pressure_filter: ${data.vars.pressure_filter}
      output:
        path: ${paths.data_dir}/normalization/model_covariance_cloud_filter_pressure_filter.npy
        type: file
    observation:
      input:
        err: ${data.vars.hofx_innovation}
        cloud_filter: ${data.vars.cloud_filter}
      output:
        path: ${paths.data_dir}/normalization/observation_covariance_cloud_filter.npy
        type: file


# Configuration for the data loader that handles the dataset splits.
loader:
  _target_: forward.model.data_loader.VarDataloader
  batch_size: 32  # Batch size for training
  num_workers: 1  # Number of workers for data loading
  sets:
    split:
      train: 0:256608
      valid: 256608:341240
      test: 341240:426872
      cloud_filter: ${data.vars.cloud_filter}
    coordinates:
      lat: ${data.vars.lat}
      lon: ${data.vars.lon}
      scans: ${data.vars.scans}
      pressure: ${data.vars.pressure}
    targets:
      prof: ${data.vars.prof}
      surf: ${data.vars.surf}
      meta: ${data.vars.meta}
      hofx: ${data.vars.hofx}
      prof_background: ${data.vars.prof_background}
      prof_increment: ${data.vars.prof_increment}
    # outputs: