# Note: This configuration file is for the ***inverse*** model.


# Configuration to download the training and testing data.
download:
  dir: ${paths.data_dir}
  url: "https://zenodo.org/record/1482223/files/GOES-16_ML_Training_Testing_Data.zip?download=1"


# TODO: Add option to fix dtype for numpy and torch
# dtype:
#   numpy:
#     _target_: numpy.float64  # Data type for arrays
#   torch:
#     _target_: torch.float64  # Data type for tensors


# Configuration for the variables used in the data loader.
vars:
  prof:
    type: ['Air temperature', 'Water vapor mixing ratio', 'Cloud ice mass', 'Cloud water mass', 'Snow mass',
           'Ice particle effective radius', 'Water particle effective radius',
           'Snow particle effective radius', 'Ozone mixing ratio']
    path: ${paths.data_dir}/Test2/prof.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.prof.path}
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        _target_: inverse.data.statistics.read_statistics_var
        _args_:
          - ${data.preparation.statistics.output.path}
          - 'prof'
      axis: null  # Axis for normalization
  surf:
    type: ['Ice area fraction', 'Land area fraction', 'Land type', 'Leaf area index', 'Soil temperature',
           'Snow area fraction', 'Snow thickness', 'Soil temperature',
           'Surface temperature (ice, land, sea, snow)', 'Wind direction', 'Wind speed',
           'Vegetation area fraction', 'Water area fraction', 'Volumetric water ratio (soil)']
    path: ${paths.data_dir}/Test2/surf.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.surf.path}
    normalization:
      _target_: forward.data.transformations.NormalizeSurface
      _partial_: false
      surfmax:
        _target_: numpy.loadtxt
        _args_:
          - forward/data/normalization/surfmax.txt
      surfmin:
        _target_: numpy.loadtxt
        _args_:
          - forward/data/normalization/surfmin.txt
  meta:
    type: ['Sensor scan angle', 'Sensor zenith angle', 'Sensor view angle', 'Sensor azimuth angle',
            'Sensor elevation angle', 'Solar azimuth angle', 'Solar zenith angle']
    path: ${paths.data_dir}/Test2/meta.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.meta.path}
    normalization:
      _target_: forward.data.transformations.NormalizeMeta
      _partial_: false
      settings:
        meta_cos_vars: [ 6 ]
        meta_scale_factor: 180
        meta_scale_offset: -180
        meta_scale_vars: [ ]
        meta_sin_vars: [ 0, 1, 2, 3, 4, 5 ]
  hofx:
    path: ${paths.data_dir}/Test2/hofx_lightning.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.hofx.path}
  lat:
    path: ${paths.data_dir}/Test2/lat.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.lat.path}
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        min: -90.0
        max: 90.0
  lon:
    path: ${paths.data_dir}/Test2/lon.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.lon.path}
  scans:
    path: ${paths.data_dir}/Test2/scans.txt
    load:
      _target_: numpy.loadtxt
      _args_:
        - ${data.vars.scans.path}
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        min: 9.0
        max: 180.0
        mean: 88.57895
        stdev: 54.53759
  pressure:
    path: ${paths.data_dir}/Test2/pressure.npy
    load:
      _target_: numpy.load
      _args_:
        - ${data.vars.pressure.path}
    normalization:
      _target_: inverse.data.transformations.min_max
      _partial_: true
      stats:
        min: 1.2935171
        max: 92814.125
        mean: 38631.695
        stdev: 34481.04
  hofx_innovation:
    load:
      _target_: inverse.data.covariance.innovation_uncertainty
      data: ${data.vars.hofx.load}
  prof_background:
    load:
      _target_: inverse.data.covariance.background_climatology
      data: ${data.vars.prof.load}
      cloud_filter: ${data.vars.cloud_filter.load}
    normalization: ${data.vars.prof.normalization}
  prof_increment:  # Note: It applies normalization to the data as specified in the data configuration.
    load:
      _target_: inverse.data.covariance.background_increment
      config_true: ${data.vars.prof}
      config_background: ${data.vars.prof_background}
  pressure_filter:
    load:
      _target_: inverse.data.filters.pressure_filter
      prof: ${data.vars.prof.load}
  cloud_filter:
    load:
      _target_: inverse.data.filters.cloud_filter
      prof: ${data.vars.prof.load}


# Preparation steps to be executed before training or evaluation.
preparation:
  statistics:
    input:
      vars:
        prof: ${data.vars.prof}
        surf: ${data.vars.surf}
        meta: ${data.vars.meta}
        hofx: ${data.vars.hofx}
        lat: ${data.vars.lat}
        lon: ${data.vars.lon}
        scans: ${data.vars.scans}
        pressure: ${data.vars.pressure}
      cloud_filter: ${data.vars.cloud_filter}
    output:
      path: ${paths.data_dir}/normalization/stats_cloud_filter.pkl
  covariance_model:
    input:
      vars:
        err: ${data.vars.prof_increment}
      cloud_filter: ${data.vars.cloud_filter}
      pressure_filter: ${data.vars.pressure_filter}
    output:
      path: ${paths.data_dir}/normalization/model_covariance_cloud_filter_pressure_filter.npy
      save:
        _target_: numpy.save
        _partial_: true
        _args_:
          - ${data.preparation.covariance_model.output.path}
      load:
        _target_: numpy.load
        _args_:
          - ${data.preparation.covariance_model.output.path}
  covariance_observation:
    input:
      vars:
        err: ${data.vars.hofx_innovation}
      cloud_filter: ${data.vars.cloud_filter}
    output:
      path: ${paths.data_dir}/normalization/observation_covariance_cloud_filter.npy
      save:
        _target_: numpy.save
        _partial_: true
        _args_:
          - ${data.preparation.covariance_observation.output.path}
      load:
        _target_: numpy.load
        _args_:
          - ${data.preparation.covariance_observation.output.path}


# Configuration for the data loader that handles the dataset splits.
loader:
  _target_: inverse.model.data_loader.InverseDataloader
  batch_size: 32  # Batch size for training
  num_workers: 1  # Number of workers for data loading
  stage:
    train:
      _target_: inverse.model.data_loader.InverseCRTMDataset
      split: 0:256608
      cloud_filter: ${data.vars.cloud_filter.load}
      coords:
        lat: ${data.vars.lat}
        lon: ${data.vars.lon}
        scans: ${data.vars.scans}
        pressure: ${data.vars.pressure}
      prof_type: ${data.vars.prof.type}
      obs:
        prof_norm: ${data.vars.prof}
        prof_norm_background: ${data.vars.prof_background}
        prof_norm_increment: ${data.vars.prof_increment}
        prof:
          load: ${data.vars.prof.load}
        prof_background:
          load: ${data.vars.prof_background.load}
        surf: ${data.vars.surf}
        meta: ${data.vars.meta}
        hofx: ${data.vars.hofx}
    valid:
      _target_: inverse.model.data_loader.InverseCRTMDataset
      split: 256608:341240
      cloud_filter: ${data.loader.stage.train.cloud_filter}
      coords: ${data.loader.stage.train.coords}
      prof_type: ${data.loader.stage.train.prof_type}
      obs: ${data.loader.stage.train.obs}
    test:
      _target_: inverse.model.data_loader.InverseCRTMDataset
      split: 341240:426872
      cloud_filter: ${data.loader.stage.train.cloud_filter}
      coords: ${data.loader.stage.train.coords}
      prof_type: ${data.loader.stage.train.prof_type}
      obs: ${data.loader.stage.train.obs}
      results:
        prof:
          path: ${paths.run_dir}/test_prof.npy
          save:
            _target_: numpy.save
            _args_:
              - ${data.loader.stage.test.results.prof.path}
          load:
            _target_: numpy.load
            _args_:
              - ${data.loader.stage.test.results.prof.path}
        hofx:
          path: ${paths.run_dir}/test_hofx.npy
          save:
            _target_: numpy.save
            _args_:
              - ${data.loader.stage.test.results.hofx.path}
          load:
            _target_: numpy.load
            _args_:
              - ${data.loader.stage.test.results.hofx.path}
    pred:
      _target_: inverse.model.data_loader.InverseCRTMDataset
      coords: ${data.loader.stage.train.coords}
      prof_type: ${data.loader.stage.train.prof_type}
      results:
        path: ${paths.run_dir}/pred_set.npy
        save:
          _target_: numpy.save
          _args_:
            - ${data.loader.stage.pred.results.path}
        load:
          _target_: numpy.load
          _args_:
            - ${data.loader.stage.pred.results.path}