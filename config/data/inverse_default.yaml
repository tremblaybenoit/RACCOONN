defaults:
  - variables/lat@stage.train.vars.lat
  - variables/lon@stage.train.vars.lon
  - variables/scans@stage.train.vars.scans
  - variables/pressure@stage.train.vars.pressure
  - variables/prof@stage.train.vars.prof
  - variables/prof_background@stage.train.vars.prof_background
  - variables/prof_increment@stage.train.vars.prof_increment
  - variables/surf@stage.train.vars.surf
  - variables/meta@stage.train.vars.meta
  - variables/hofx@stage.train.vars.hofx
  - variables/hofx_innovation@stage.train.vars.hofx_innovation
  - variables/cloud_filter@stage.train.vars.cloud_filter
  - variables/lat@stage.predict.vars.lat
  - variables/lon@stage.predict.vars.lon
  - variables/scans@stage.predict.vars.scans
  - variables/pressure@stage.predict.vars.pressure

# Configuration to download the training and testing data
download:
  dir: ${paths.data_dir}
  url: "https://zenodo.org/record/1482223/files/GOES-16_ML_Training_Testing_Data.zip?download=1"

# Pressure filter
pressure_filter:
  load:
    _target_: inverse.data.filters.pressure_filter
    prof:
      _target_: forward.utilities.io.load_stack
      stack:
        - ${data.stage.train.vars.prof}
        - ${data.stage.valid.vars.prof}
        - ${data.stage.test.vars.prof}

# Split the data into training, validation, and test sets
stage:
  # Training set
  train:
    # Path to training data
    dir: ${paths.data_dir}/Train2
    # Split
    split:
      _target_: forward.utilities.io.extract_indices
      _args_:
        - _target_: numpy.arange
          _args_:
            - 0
            - 256608
        - _target_: ${data.stage.train.vars.cloud_filter.load._target_}
          _args_:
            - _target_: ${data.stage.train.vars.prof.load._target_}
              path: ${data.stage.train.vars.prof.load.path}
    # Variables
    vars:
      # Atmospheric profiles
      prof:
        # Normalization function and parameters
        normalization:
          _target_: inverse.data.transformations.min_max
          _partial_: true
          stats:
            _target_: inverse.data.statistics.read_statistics_var
            _args_:
              - ${preparation.statistics.data.output.path}
              - 'prof'
          axis: 1  # null
  # Validation set
  valid:
    # Path to validation data
    dir: ${paths.data_dir}/Valid2
    # Split
    split:
      _target_: forward.utilities.io.extract_indices
      _args_:
        - _target_: numpy.arange
          _args_:
            - 256608
            - 320760
        - _target_: ${data.stage.valid.vars.cloud_filter.load._target_}
          _args_:
            - _target_: ${data.stage.valid.vars.prof.load._target_}
              path: ${data.stage.valid.vars.prof.load.path}
    # Variables
    vars: ${data.stage.train.vars}
  # Test set
  test:
    # Path to test data
    dir: ${paths.data_dir}/Test2
    # Split
    split:
      _target_: forward.utilities.io.extract_indices
      _args_:
        - _target_: numpy.arange
          _args_:
            - 320760
            - 426872
        - _target_: ${data.stage.test.vars.cloud_filter.load._target_}
          _args_:
            - _target_: ${data.stage.test.vars.prof.load._target_}
              path: ${data.stage.test.vars.prof.load.path}
    # Variables
    vars: ${data.stage.train.vars}
  # Prediction set (NOTE: By default, we use the test set as the prediction set for demonstration purposes)
  predict:
    # Path to prediction data
    dir: ${paths.data_dir}/Test2
    # Split
    split: ${data.stage.test.split}