# Model
_target_: inverse.model.model.PINNverseOperator
_recursive_: false

# Optimizer function and parameters
optimizer:
  # Function
  _target_: torch.optim.Adam
  # Learning rate
  lr: 0.0005
  # Weight decay (L2 regularization)
  weight_decay: 0.000

# Learning rate scheduler
lr_scheduler:
  # Function
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  # Mode for the scheduler
  mode: min
  # Factor to reduce the learning rate
  factor: 0.2
  # Number of epochs with no improvement after which learning rate will be reduced
  patience: 3
  # Minimum learning rate
  min_lr: 1.0e-6
  # Threshold for measuring the new optimum, to only focus on significant changes
  threshold: 0.01

# Model parameters associated with the data (e.g., input/output dimensions) and architecture
parameters:
  # Data parameters
  data:
    # Number of variables
    n_lat: 1
    n_lon: 1
    n_scans: 1
    n_prof: 9
    n_levels: 1
    n_pressure: 1
    n_cloud: 0
    # Profile variables (input/output)
    prof_vars: ${data.stage.train.vars.prof.type}
  # Model architecture
  architecture:
    # Number of neurons in the hidden layers
    n_neurons: 64
    # Number of hidden layers
    n_layers: 4
    # Dropout rate
    dropout: 0.1

# Loss function and parameters
loss_func:
  # Function
  _target_: inverse.model.loss.VarLoss # Load loss function
  # Forward model to compute the model equivalent of the observations
  forward_model:
    # Function
    _target_: inverse.model.loss.ForwardModel
    # Precision
    dtype: ${data.dtype}
    # Normalization for the profile variables
    prof_norm: null
  # Weights for observation (obs), model, and boundary condition (bcs) errors
  lambda_obs: 0.
  lambda_model: 1.
  lambda_bcs: 1.
  # Loss term for observations
  loss_obs:
    _target_: inverse.model.loss.MSE
  # Loss term for model variables
  loss_model:
    _target_: inverse.model.loss.MSE
  # Loss term for boundary conditions
  loss_bcs:
    _target_: inverse.model.loss.MSE
  # Pressure filter: Consider only pressure levels with non-zero variance (for model and bcs errors)
  pressure_filter:  ${data.pressure_filter.load}

# Positional encoding
positional_encoding:
  _target_: inverse.model.encoding.IdentityPositionalEncoding

# Activation functions (input layer/within the network)
activation_in:
  _target_: forward.model.activation.Sine

# Activation function (output layer)
activation_out:
  _target_: torch.nn.Sigmoid

# Transformations (to apply after the output layer)
transform_out: null