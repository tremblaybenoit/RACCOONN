_target_: inverse.model.model.PINNverseOperator

# Optimizer function and parameters
optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.000

# Learning rate scheduler
lr_scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.2  # factor_lr_reduce
  patience: 3  # patience_lr
  min_lr: 1.0e-6  # learning_rate_min
  threshold: 0.01  # mindelta_lr_reduce

# Model parameters
parameters:
  data:
    # Number of variables
    n_lat: 1
    n_lon: 1
    n_scans: 1
    n_prof: 9
    n_levels: 1
    n_pressure: 1
    n_cloud: 0
    prof_vars: ${data.vars.prof.type}

  architecture:
    n_neurons: 64  # Number of neurons in the hidden layers
    n_layers: 4  # Number of hidden layers
    dropout: 0.1  # Dropout rate

# Loss term(s)
  loss_func:
    _target_: inverse.model.loss.VarLoss # Load loss function
    _partial_: false  # Partial instantiation for callable
    forward_model:
      _target_: inverse.model.loss.ForwardModel
      prof_norm:
        _target_: forward.data.transformations.NormalizeProfiles
        profmax:
          _target_: numpy.loadtxt
          _args_:
            - forward/data/normalization/prof_div.txt
      profmin:
        _target_: numpy.loadtxt
        _args_:
          - forward/data/normalization/prof_m.txt
    lambda_obs: 1.  # Weight for observation error in the observation space
    lambda_model: 1.  # Weight for background error
    lambda_bcs: 1.  # Weight for boundary conditions error
    loss_obs:
      _target_: inverse.model.loss.mse
    loss_model:
      _target_: inverse.model.loss.mse
    loss_bcs:
      _target_: inverse.model.loss.mse
    pressure_filter:  ${data.vars.pressure_filter.load}  # Mask zero-variance pressure levels

# Positional encoding
positional_encoding:
  _target_: inverse.model.encoding.IdentityPositionalEncoding
  _partial_: true

# Activation functions (input layer/within the network)
activation_in:
  _target_: forward.model.activation.Sine
  _partial_: true

# Activation function (output layer)
activation_out:
  _target_: torch.nn.Sigmoid
  _partial_: true

# Transformations (output layer)
transform: ${data.vars.prof.normalization}
# Transformations (loss function)
inverse_transform:
  _target_: ${model.transform._target_}
  _partial_: true
  stats: ${model.transform.stats}
  axis: ${model.transform.axis}  # Axis for normalization
  inverse_transform: true

# Clip output values
clip: null

# Plot logger
log_valid: true