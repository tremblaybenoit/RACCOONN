# @package _global_
# Experiment-specific Hydra structure

# Overriding default structure
defaults:
  - override /paths: default
  - override /hydra: default
  - override /data: inverse_default
  - override /preparation: inverse_default
  - override /loader: inverse_default
  - override /model: inverse_operator
  - override /trainer: gpu
  - override /callbacks: default
  - override /logger: default

# All parameters below will be merged with parameters from default configurations set above.
# This allows you to overwrite only specified parameters

# Task name. Note that it determines the output directory path
task_name: "inverse_operators"  # Experiment

# Run id (unique identifier for the run)
paths:
  task_dir: "../inverse_outputs"
  run_id: "version_001"
  data_dir: "../../GOES_ML-main/Data"

# Logger configuration
logger:
  # Ports
  ports:
    mlflow: 5001  # MLflow port

# Trainer configuration
trainer:
  min_epochs: 1  # To prevent early stopping
  max_epochs: 32  # Number of epochs

# Data configuration
data:
  # Split ratios for training, validation, and test sets
  stage:
    # Training set
    train:
      # Variables
      vars:
        # Atmospheric profiles
        prof:
          # Normalization function and parameters
          normalization:
            _target_: inverse.data.transformations.min_max
            _partial_: true
            stats:
              _target_: inverse.data.statistics.read_statistics_var
              _args_:
                - ${preparation.statistics.data.output.path}
                - 'prof'
            axis: 1  # null
    # Validation set
    valid:
      # Variables
      vars:
        # Atmospheric profiles
        prof:
          # Normalization function and parameters
          normalization: ${data.stage.train.vars.prof.normalization}
    # Test set
    test:
      # Variables
      vars:
        # Atmospheric profiles
        prof:
          # Normalization function and parameters
          normalization: ${data.stage.train.vars.prof.normalization}

# Loader configuration
loader:
  # Stage
  stage:
    # Training set
    train:
      # Targets
      target:
        prof_norm_background: ${data.stage.train.vars.prof}
        prof_background:
          load: ${data.stage.train.vars.prof.load}
    # Validation set
    valid:
      # Targets
      target:
        prof_norm_background: ${data.stage.valid.vars.prof}
        prof_background:
          load: ${data.stage.valid.vars.prof.load}
    # Test set
    test:
      # Targets
      target:
        prof_norm_background: ${data.stage.test.vars.prof}
        prof_background:
          load: ${data.stage.test.vars.prof.load}

# Model parameters
model:
  # Model
  _target_: inverse.model.model.PINNverseOperators
  # Optimizer function and parameters
  optimizer:
    # Learning rate
    lr: 0.001
    # Weight decay (L2 regularization)
    weight_decay: 0.000
  # Learning rate scheduler
  lr_scheduler: null
  #  # Function
  #  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  #  # Mode for the scheduler
  #  mode: min
  #  # Factor to reduce the learning rate
  #  factor: 0.2
  #  # Number of epochs with no improvement after which learning rate will be reduced
  #  patience: 3
  #  # Minimum learning rate
  #  min_lr: 1.0e-6
  #  # Threshold for measuring the new optimum, to only focus on significant changes
  #  threshold: 0.01
  # Model parameters associated with the data (e.g., input/output dimensions) and architecture
  parameters:
    # Model architecture
    architecture:
      # Number of neurons in the hidden layers
      n_neurons: 64
      # Number of hidden layers
      n_layers: 4
      # Dropout rate
      dropout: 0.1
  # Loss function and parameters
  loss_func:
    # Weights for observation (obs), model, and boundary condition (bcs) errors
    lambda_obs: 0.
    lambda_model: 1.
    lambda_bcs: 10000.
    # Loss term for observations
    loss_obs:
      _target_: inverse.model.loss.MSE
    # Loss term for model variables
    loss_model:
      _target_: inverse.model.loss.MSE
    # Loss term for boundary conditions
    loss_bcs:
      _target_: inverse.model.loss.MSE
    # Pressure filter: Consider only pressure levels with non-zero variance (for model and bcs errors)
    pressure_filter: ${data.pressure_filter.load}
  # Positional encoding
  positional_encoding:
    _target_: inverse.model.encoding.IdentityPositionalEncoding
  # Activation functions (input layer/within the network)
  activation_in:
    _target_: forward.model.activation.Sine
  # Activation function (output layer)
  activation_out:
    _target_: torch.nn.Sigmoid