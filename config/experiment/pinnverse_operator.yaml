# @package _global_
# Experiment-specific Hydra structure

# Overriding default structure
defaults:
  - override /data: inverse
  - override /preparation: inverse
  - override /loader: inverse
  - override /paths: default
  - override /hydra: default
  - override /model: pinnverse_operator
  - override /trainer: gpu
  - override /callbacks: default
  - override /logger: default

# All parameters below will be merged with parameters from default configurations set above.
# This allows you to overwrite only specified parameters

# Task name. Note that it determines the output directory path
task_name: "pinnverse_operator"  # Experiment

# Run id (unique identifier for the run)
paths:
  task_dir: "../inverse_outputs"
  run_id: "version_000"
  data_dir: "../../GOES_ML-main/Data"

# Trainer configuration
trainer:
  min_epochs: 1  # To prevent early stopping
  max_epochs: 32  # Number of epochs

# Model parameters
model:
  _target_: inverse.model.model.PINNverseOperator

  # Optimizer function and parameters
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 0.000

  # Learning rate scheduler
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.2  # factor_lr_reduce
    patience: 3  # patience_lr
    min_lr: 1.0e-6  # learning_rate_min
    threshold: 0.01  # mindelta_lr_reduce

  # Model parameters
  parameters:

    architecture:
      n_neurons: 64  # Number of neurons in the hidden layers
      n_layers: 4  # Number of hidden layers
      dropout: 0.1  # Dropout rate

    # Loss term(s)
    loss_func:
      _target_: inverse.model.loss.VarLoss # Load loss function
      _partial_: false  # Partial instantiation for callable
      forward_model:
        _target_: inverse.model.loss.ForwardModel
        prof_norm:
          _target_: forward.data.transformations.NormalizeProfiles
          profmax:
            _target_: numpy.loadtxt
            _args_:
              - forward/data/normalization/prof_div.txt
        profmin:
          _target_: numpy.loadtxt
          _args_:
            - forward/data/normalization/prof_m.txt
      lambda_obs: 0.  # Weight for observation error in the observation space
      lambda_model: 1.  # Weight for background error
      lambda_bcs: 1.  # Weight for boundary conditions error
      loss_obs:
        _target_: inverse.model.loss.mse
      loss_model:
        _target_: inverse.model.loss.mse
      loss_bcs:
        _target_: inverse.model.loss.mse
      pressure_filter: ${data.vars.pressure_filter.load}  # Mask zero-variance pressure levels

  # Positional encoding
  positional_encoding:
    _target_: inverse.model.encoding.IdentityPositionalEncoding
    _partial_: true

  # Activation functions (input layer/within the network)
  activation_in:
    _target_: forward.model.activation.Sine
    _partial_: true

  # Activation function (output layer)
  activation_out:
    _target_: torch.nn.Sigmoid
    _partial_: true

  # Transformations (output layer)
  transform: ${data.vars.prof.normalization}
  # Transformations (loss function)
  inverse_transform:
    _target_: ${model.transform._target_}
    _partial_: true
    stats: ${model.transform.stats}
    axis: ${model.transform.axis}  # Axis for normalization
    inverse_transform: true

  # Clip output values
  clip: null
